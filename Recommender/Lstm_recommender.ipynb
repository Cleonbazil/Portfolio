{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b45cfed-1596-4145-b428-e1220e17c104",
   "metadata": {},
   "source": [
    "### Long short term memory (LSTM) Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f5892-8ada-4d17-90de-ad3d07cefe9b",
   "metadata": {},
   "source": [
    "- Cell state : Represents the long term memory, ther are not any weights and/or biases to modify it directly thus avoiding the<br>\n",
    "exploding/vanishing gradient problem.\n",
    "\n",
    "- Hidden state : Represents the shor term memory\n",
    "\n",
    "#### First stage\n",
    "##### Inputs\n",
    "- Previous long term memory =  $L_{t1}$            \n",
    "- Previous short term memormy = $S_{t1}$\n",
    "- First input = $x_1$\n",
    "\n",
    "##### Weights\n",
    "- Long term memory weight = $w_{l1}$\n",
    "- Short term memory weight = $w_{s1}$\n",
    "- Input weight = $w_1$\n",
    "\n",
    "##### Activation function\n",
    "- $Sigmoid$\n",
    "\n",
    "$z_{\\_first} = (x_1\\,*\\,w_1) + (S_{t1}\\,*\\,w_{s1}) + b_1$<br>\n",
    "$y_{\\_first} = \\sigma(z_{\\_first})$<br>\n",
    "Percentage of the previous Long-term memory preserved = $y_1 * L_{t1}$\n",
    "\n",
    "Since the activation function used is the sigmoid function which outputs a number between 0-1, in this first stage what it is being determined is the<br>\n",
    "percentage of the Long-term memory that will be remembered, this first stage of the lstm is also known as the $Forget gate$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04792455-84d7-4fc8-ae13-d5e7b550d8c4",
   "metadata": {},
   "source": [
    "#### Second Stage\n",
    "The second stage consists of three parts: \n",
    "\n",
    "- First part: the short-term memory is combined with the input to create a potential long term memory.\n",
    "  ##### Activation function\n",
    "- $Tan-h$<br>\n",
    "\n",
    "$z_{2-1} = (x_1\\,*\\,w_{2-1}) + (S_{t1}\\,*\\,w_{s2-1}) + b_{2-1}$<br>\n",
    "$y_{2-1} = \\sigma(z_{2-1})$<br>\n",
    "\n",
    "\n",
    "\n",
    "- Second part: the input is used to comupte the percentage of the potential long term memory is preserved.\n",
    "##### Activation function\n",
    "- $Sigmoid$\n",
    "\n",
    "\n",
    "$z_{2-2} = (x_1\\,*\\,w_{2-2}) + (S_{t1}\\,*\\,w_{s2-2}) + b_{2-2}$<br>\n",
    "$y_{2-2} = \\sigma(z_{2-2})$<br>\n",
    "\n",
    "\n",
    "- Third part: In this step the potential long term memory is multiplied by the percentage and subsequently added to the long term memory generating a new long term memory.<br>\n",
    "\n",
    "$L_{t2} = (y_{2-1} *  y_{2-2}) +  (y_1 * L_{t1})$\n",
    "\n",
    "The entire process above which encompasses the firs and second state is denominated the $$Input\\:Gate$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e5617-0495-45c9-b0bb-aba0bb06a909",
   "metadata": {},
   "source": [
    "#### Third stage\n",
    "\n",
    "In this stage we take the new long term memory and pass it through a tan-h function to generate a short term memory, aftewards we calculate what percentage of it will be preserved.\n",
    "\n",
    "- Part 1 generating the new short term memory\n",
    " ##### Activation function\n",
    "- $Tan-h$<br>\n",
    "\n",
    "$z_{3-1} = L_{t2}$<br>\n",
    "$y_{3-1} = \\sigma(z_{3-1})$<br>\n",
    "\n",
    "- Part 2 determining percentage preserved<br>\n",
    "$z_{3-2} = (x_1\\,*\\,w_{3-2}) + (S_{t1}\\,*\\,w_{s3-2}) + b_{2-2}$<br>\n",
    "$y_{3-2} = \\sigma(z_{3-2})$<br>\n",
    "\n",
    "- Part 3 Generating new short term memory<br>\n",
    "\n",
    "$S_{t2} = y_{3-1} * \\:y_{3-2}$\n",
    "\n",
    "The third stage generates the output of the lstm thus this step is called the $Output\\: Gate$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d9242a-e018-4063-b486-b1b201c21099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c78d34b-ab6d-4e90-82ce-2b9cfc388362",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fcd77a1-598b-4584-ad2d-623795989cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chris\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D\n",
    "\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb # new! \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences #new!\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout,Activation,BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding # new!\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint # new! \n",
    "\n",
    "from tensorflow.keras.layers import SimpleRNN # new! \n",
    "from tensorflow.keras.layers import LSTM # new! \n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ba551-a84a-4bcf-9744-8cf49cb63cb6",
   "metadata": {},
   "source": [
    "#### Loading Data\n",
    "For a given data set: \n",
    "\n",
    "* The TensorFlow Keras module's text utilities [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text) quickly preprocess natural language and convert it into an index\n",
    "* The `Tokenizer` class covered therein may do everything you need in a single line of code:\n",
    "    * tokenize into words or characters\n",
    "    * `num_words`: maximum unique tokens\n",
    "    * filter out punctuation\n",
    "    * lower case\n",
    "    * convert words to an integer index\n",
    "* Other natural language preprocessing steps you may want to consider for your particular dataset and application are covered in the [*Natural Language Preprocessing* notebook](https://github.com/jonkrohn/DLTFpT/blob/master/notebooks/natural_language_preprocessing.ipynb), including: \n",
    "    * removing stop words\n",
    "    * either stemming or lemmatization\n",
    "    * colocating n-grams, such as bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55a6caf-f6a7-4b5d-bb08-4ee817e4bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As per Maas et al. (2011)\n",
    "\n",
    "#The number of unique words included in the word vector space are set in this case to be the 5000 most occuring words that are not the 50 most occuring\n",
    "#this may not be optimal and can be adjusted\n",
    "n_unique_words = 10000\n",
    "\n",
    "#The number of words to skip or stop words the 50 most occurring words in the corpus,this may not be optimal and can be adjusted\n",
    "n_words_to_skip = 100\n",
    "\n",
    "(X_train, y_train), (X_valid, y_valid) = imdb.load_data(num_words=n_unique_words, \n",
    "                                                        skip_top=n_words_to_skip) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c40d9-eed3-464f-a2cb-43f92875fc67",
   "metadata": {},
   "source": [
    "#### Mapping word to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d48ccf3-0dd1-4f42-aa49-63c9e36dadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "word_index = {key:(value+3) for key,value in word_index.items()}\n",
    "word_index['PAD'] = 0\n",
    "word_index['START'] = 1\n",
    "word_index['UNK'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2b4b1-e234-485e-8b89-4d0e79fb5358",
   "metadata": {},
   "source": [
    "#### Flipping index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91192b07-ae77-4496-af48-20e7dada0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {value:key for key,value in word_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4538e02-dc6d-4626-bd3d-626b4f66e4e9",
   "metadata": {},
   "source": [
    "#### Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e1dea7-9d35-457e-ba3e-a081680521b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When using tensorflow keras it is necessary to establish the length of the reviews if the review is larger than the preset number it is truncated to the\n",
    "#the preset number of words, if it is smaller it is padded to reach the preset number of words\n",
    "\n",
    "#The max_review_length = 100 was increased to 400 because in this example we are using Convolutional Neural Networks which allow the model to handel a \n",
    "#larger review length mainly due to max pooling layer.\n",
    "max_review_length = 100 # length of review\n",
    "\n",
    "#Padding review at the beginning \n",
    "pad_type = 'pre' \n",
    "#Truncating review at the beginning\n",
    "trunc_type = 'pre'\n",
    "\n",
    "padding_value = 0 # value used for padding\n",
    "\n",
    "X_train = pad_sequences(\n",
    "                        X_train,\n",
    "                        maxlen = max_review_length,\n",
    "                        padding = pad_type,\n",
    "                        truncating = trunc_type,\n",
    "                        value = padding_value\n",
    "                       )\n",
    "\n",
    "X_valid = pad_sequences(\n",
    "                        X_valid,\n",
    "                        maxlen = max_review_length,\n",
    "                        padding = pad_type,\n",
    "                        truncating = trunc_type,\n",
    "                        value = padding_value\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84687ee6-7182-4de8-8aa0-188a9ae106dc",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93da7ea-e689-474d-8f22-45389e8340bf",
   "metadata": {},
   "source": [
    "#### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4e62393-3e28-4fb5-b8f8-840994d204f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding layer\n",
    "#The number of dimensions of the work vector space\n",
    "number_of_dimensions = 64\n",
    "## Dropout rate for embedding layer\n",
    "embedding_dropout_rate = 0.2\n",
    "############################################################\n",
    "#Denselayer\n",
    "#Number of neurons in the Dense layers\n",
    "dense_neurons= 256\n",
    "#Drop out rate for dense layers \n",
    "dense_dropout_rate = 0.2\n",
    "##############################################################\n",
    "#RNN layer\n",
    "#Number of neurons in the Dense layers\n",
    "rnn_neurons= 256\n",
    "#Drop out rate for dense layers \n",
    "rnn_dropout_rate = 0.2\n",
    "#########################################\n",
    "#LSTM layer\n",
    "#Number of neurons in the Dense layers\n",
    "lstm_neurons= 256\n",
    "#Drop out rate for dense layers \n",
    "lstm_dropout_rate = 0.2\n",
    "#########################################\n",
    "\n",
    "\n",
    "#Activation fucntion\n",
    "activation_function = 'relu'\n",
    "\n",
    "############################################\n",
    "#Convolutional layer\n",
    "number_conv_filters = 256\n",
    "#kernel window size is 3 since we are looking for trigrams\n",
    "kernel_conv = 3\n",
    "\n",
    "#Output activation function\n",
    "activation_function_output='sigmoid'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e97817-e0b7-44ec-b84a-6fb06b741979",
   "metadata": {},
   "source": [
    "#### Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df7ae202-539f-49bb-9d0b-3612bb07ec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chris\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 64)           640000    \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 100, 64)           0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               328704    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 968961 (3.70 MB)\n",
      "Trainable params: 968961 (3.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = Sequential()\n",
    "\n",
    "## Input layer and firs hidden layer\n",
    "### Embedding layer\n",
    "##Creating the word vector space\n",
    "model.add(\n",
    "          Embedding(\n",
    "                     n_unique_words,\n",
    "                    number_of_dimensions,\n",
    "                    input_length = max_review_length #input layer\n",
    "                   )\n",
    "          )\n",
    "##Embedding Dropout layer\n",
    "model.add(SpatialDropout1D(embedding_dropout_rate))\n",
    "##################################################################################################################\n",
    "###Second hidden layer\n",
    "model.add(\n",
    "          LSTM(\n",
    "                    lstm_neurons,\n",
    "                    dropout = lstm_dropout_rate\n",
    "                   )\n",
    "         )\n",
    "#####################################################################################################################\n",
    "##Output\n",
    "model.add(\n",
    "          Dense(\n",
    "                1,\n",
    "                activation = activation_function_output\n",
    "              )\n",
    "        )\n",
    "\n",
    "#####################################################################################################################\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186eabf5-c9d1-49b9-86e9-00aa3290ed97",
   "metadata": {},
   "source": [
    "#### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eeeeacf-3bfe-41bc-9cf1-fd1b5bcac523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Chris\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_function = 'binary_crossentropy'\n",
    "optimizer = 'nadam'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(\n",
    "               loss = loss_function,\n",
    "               optimizer = optimizer,\n",
    "               metrics = metrics\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d544ac-c654-4c9e-ba27-ab55214e6f68",
   "metadata": {},
   "source": [
    "#### Saving weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eedc4ef-9dcf-4486-b759-f6eed1802680",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_output/lstm'\n",
    "modelcheckpoint = ModelCheckpoint(filepath = output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e8cc4-0ed0-4a36-8446-bf6467e45ae9",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8ca2255-2923-440b-8641-96f4338494d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "WARNING:tensorflow:From C:\\Users\\Chris\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Chris\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "196/196 [==============================] - 222s 1s/step - loss: 0.5940 - accuracy: 0.6678 - val_loss: 0.4063 - val_accuracy: 0.8224\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 149s 760ms/step - loss: 0.3277 - accuracy: 0.8594 - val_loss: 0.3621 - val_accuracy: 0.8416\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 145s 743ms/step - loss: 0.2548 - accuracy: 0.8980 - val_loss: 0.3811 - val_accuracy: 0.8321\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 139s 712ms/step - loss: 0.2158 - accuracy: 0.9154 - val_loss: 0.4064 - val_accuracy: 0.8198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2763fa6a610>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 4\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "model.fit(\n",
    "          X_train,y_train,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs = EPOCHS,\n",
    "          validation_data = (X_valid,y_valid),\n",
    "          callbacks = [modelcheckpoint]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de49ad-ca1e-4e6f-8822-12bf5347d6c9",
   "metadata": {},
   "source": [
    "#### Loading Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "740a18a5-e977-4a2d-820e-16b498ae9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.02.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44f8f1-e95b-44af-98e8-72968d688699",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f3d57d6-494a-47c6-a863-c380f9720e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 61s 76ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAGdCAYAAADjWSL8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoHklEQVR4nO3dfXBU53n+8WutlYSQpRMQ1i4KCpZTmUCEHSJisXJdaAABRVYzTCq3crekQwAXG6wApVD6qyHjSjYdA3EVU0ypIbxETl0r9TT2BjFNFDCIFwVNeSt2A7ZRrUXgLCsJyysQ5/cH5TSLCGaF3h75+5k5M9pn7z17n2dkzuVH5+y6bNu2BQAAYJi7+roBAACAriDEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACM5O7rBnrK1atX9eGHHyolJUUul6uv2wEAALfBtm21tLQoIyNDd91167WWARtiPvzwQ2VmZvZ1GwAAoAvOnj2rESNG3LJmwIaYlJQUSdcmITU1tY+7AdBtrlySXs+49vOsDyV3ct/2A6BbNTc3KzMz0zmP38qADTHX/4SUmppKiAEGkitx0uD//Tk1lRADDFC3cykIF/YCAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGMnd1w0AAADp3uU/6esWYvbeczP79P1ZiQEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjBRziPmf//kf/emf/qnS0tI0ePBgfeUrX1FdXZ3zvG3bWrVqlTIyMpSUlKRJkybp+PHjUfuIRCJauHChhg0bpuTkZBUVFamhoSGqJhQKye/3y7IsWZYlv9+vixcvdu0oAQDAgBNTiAmFQnr44YcVHx+vt956SydOnNALL7ygz33uc07NmjVrtHbtWlVUVOjQoUPyer2aOnWqWlpanJrS0lJVVVWpsrJSe/fuVWtrqwoLC9XR0eHUlJSUqL6+XoFAQIFAQPX19fL7/Xd+xAAAYEBw2bZt327x8uXL9fbbb2vPnj03fd62bWVkZKi0tFR/9Vd/JenaqovH49Hzzz+v+fPnKxwO65577tG2bdv02GOPSZI+/PBDZWZm6s0339S0adN08uRJjRkzRrW1tcrLy5Mk1dbWyufz6b/+6780atSoT+21ublZlmUpHA4rNTX1dg8RQH935ZL0o7uv/VzcKrmT+7YfoJvwtQPXxHL+jmkl5o033tD48eP1R3/0R0pPT9e4ceO0adMm5/kzZ84oGAyqoKDAGUtMTNTEiRO1b98+SVJdXZ0uX74cVZORkaGcnBynZv/+/bIsywkwkjRhwgRZluXU3CgSiai5uTlqAwAAA1dMIeb06dPasGGDsrOz9dOf/lRPPPGEFi1apB/84AeSpGAwKEnyeDxRr/N4PM5zwWBQCQkJGjJkyC1r0tPTO71/enq6U3Oj8vJy5/oZy7KUmZkZy6EBAADDxBRirl69qq9+9asqKyvTuHHjNH/+fM2dO1cbNmyIqnO5XFGPbdvuNHajG2tuVn+r/axYsULhcNjZzp49e7uHBQAADBRTiBk+fLjGjBkTNTZ69Gh98MEHkiSv1ytJnVZLmpqanNUZr9er9vZ2hUKhW9acO3eu0/ufP3++0yrPdYmJiUpNTY3aAADAwBVTiHn44Yd16tSpqLF33nlHI0eOlCRlZWXJ6/Wqurraeb69vV01NTXKz8+XJOXm5io+Pj6qprGxUceOHXNqfD6fwuGwDh486NQcOHBA4XDYqQEAAJ9t7liKv/Od7yg/P19lZWUqLi7WwYMH9fLLL+vll1+WdO1PQKWlpSorK1N2drays7NVVlamwYMHq6SkRJJkWZbmzJmjJUuWKC0tTUOHDtXSpUs1duxYTZkyRdK11Z3p06dr7ty52rhxoyRp3rx5KiwsvK07kwAAwMAXU4j52te+pqqqKq1YsULf/e53lZWVpfXr1+vxxx93apYtW6a2tjYtWLBAoVBIeXl52rVrl1JSUpyadevWye12q7i4WG1tbZo8ebK2bNmiuLg4p2bHjh1atGiRcxdTUVGRKioq7vR4AQDAABHT58SYhM+JAQYoPicGAxSfE3NNj31ODAAAQH9BiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIMYWYVatWyeVyRW1er9d53rZtrVq1ShkZGUpKStKkSZN0/PjxqH1EIhEtXLhQw4YNU3JysoqKitTQ0BBVEwqF5Pf7ZVmWLMuS3+/XxYsXu36UAABgwIl5JebLX/6yGhsbne3o0aPOc2vWrNHatWtVUVGhQ4cOyev1aurUqWppaXFqSktLVVVVpcrKSu3du1etra0qLCxUR0eHU1NSUqL6+noFAgEFAgHV19fL7/ff4aECAICBxB3zC9zuqNWX62zb1vr167Vy5UrNmjVLkrR161Z5PB7t3LlT8+fPVzgc1ubNm7Vt2zZNmTJFkrR9+3ZlZmZq9+7dmjZtmk6ePKlAIKDa2lrl5eVJkjZt2iSfz6dTp05p1KhRd3K8AABggIh5Jebdd99VRkaGsrKy9Md//Mc6ffq0JOnMmTMKBoMqKChwahMTEzVx4kTt27dPklRXV6fLly9H1WRkZCgnJ8ep2b9/vyzLcgKMJE2YMEGWZTk1AAAAMa3E5OXl6Qc/+IHuv/9+nTt3Ts8++6zy8/N1/PhxBYNBSZLH44l6jcfj0fvvvy9JCgaDSkhI0JAhQzrVXH99MBhUenp6p/dOT093am4mEokoEok4j5ubm2M5NAAAYJiYQsyMGTOcn8eOHSufz6cvfvGL2rp1qyZMmCBJcrlcUa+xbbvT2I1urLlZ/aftp7y8XKtXr76t4wAAAOa7o1usk5OTNXbsWL377rvOdTI3rpY0NTU5qzNer1ft7e0KhUK3rDl37lyn9zp//nynVZ7ftGLFCoXDYWc7e/bsnRwaAADo52K+sPc3RSIRnTx5Uo888oiysrLk9XpVXV2tcePGSZLa29tVU1Oj559/XpKUm5ur+Ph4VVdXq7i4WJLU2NioY8eOac2aNZIkn8+ncDisgwcP6qGHHpIkHThwQOFwWPn5+b+1l8TERCUmJt7J4cTk3uU/6bX36i7vPTezr1sAAKDbxBRili5dqkcffVRf+MIX1NTUpGeffVbNzc2aPXu2XC6XSktLVVZWpuzsbGVnZ6usrEyDBw9WSUmJJMmyLM2ZM0dLlixRWlqahg4dqqVLl2rs2LHO3UqjR4/W9OnTNXfuXG3cuFGSNG/ePBUWFnJnEgAAcMQUYhoaGvQnf/InunDhgu655x5NmDBBtbW1GjlypCRp2bJlamtr04IFCxQKhZSXl6ddu3YpJSXF2ce6devkdrtVXFystrY2TZ48WVu2bFFcXJxTs2PHDi1atMi5i6moqEgVFRXdcbwAAGCAcNm2bfd1Ez2hublZlmUpHA4rNTW12/fPn5OAPnLlkvSju6/9XNwquZP7th+gm3BeuSaW8zffnQQAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGCkOwox5eXlcrlcKi0tdcZs29aqVauUkZGhpKQkTZo0ScePH496XSQS0cKFCzVs2DAlJyerqKhIDQ0NUTWhUEh+v1+WZcmyLPn9fl28ePFO2gUAAANIl0PMoUOH9PLLL+uBBx6IGl+zZo3Wrl2riooKHTp0SF6vV1OnTlVLS4tTU1paqqqqKlVWVmrv3r1qbW1VYWGhOjo6nJqSkhLV19crEAgoEAiovr5efr+/q+0CAIABpkshprW1VY8//rg2bdqkIUOGOOO2bWv9+vVauXKlZs2apZycHG3dulUff/yxdu7cKUkKh8PavHmzXnjhBU2ZMkXjxo3T9u3bdfToUe3evVuSdPLkSQUCAf3TP/2TfD6ffD6fNm3apH//93/XqVOnuuGwAQCA6boUYp588knNnDlTU6ZMiRo/c+aMgsGgCgoKnLHExERNnDhR+/btkyTV1dXp8uXLUTUZGRnKyclxavbv3y/LspSXl+fUTJgwQZZlOTU3ikQiam5ujtoAAMDA5Y71BZWVlfrlL3+pQ4cOdXouGAxKkjweT9S4x+PR+++/79QkJCREreBcr7n++mAwqPT09E77T09Pd2puVF5ertWrV8d6OAAAwFAxrcScPXtWTz/9tLZv365Bgwb91jqXyxX12LbtTmM3urHmZvW32s+KFSsUDoed7ezZs7d8PwAAYLaYQkxdXZ2ampqUm5srt9stt9utmpoavfjii3K73c4KzI2rJU1NTc5zXq9X7e3tCoVCt6w5d+5cp/c/f/58p1We6xITE5Wamhq1AQCAgSumEDN58mQdPXpU9fX1zjZ+/Hg9/vjjqq+v13333Sev16vq6mrnNe3t7aqpqVF+fr4kKTc3V/Hx8VE1jY2NOnbsmFPj8/kUDod18OBBp+bAgQMKh8NODQAA+GyL6ZqYlJQU5eTkRI0lJycrLS3NGS8tLVVZWZmys7OVnZ2tsrIyDR48WCUlJZIky7I0Z84cLVmyRGlpaRo6dKiWLl2qsWPHOhcKjx49WtOnT9fcuXO1ceNGSdK8efNUWFioUaNG3fFBAwAA88V8Ye+nWbZsmdra2rRgwQKFQiHl5eVp165dSklJcWrWrVsnt9ut4uJitbW1afLkydqyZYvi4uKcmh07dmjRokXOXUxFRUWqqKjo7nYBAIChXLZt233dRE9obm6WZVkKh8M9cn3Mvct/0u377GnvPTezr1sA7tyVS9KP7r72c3Gr5E7u236AbsJ55ZpYzt98dxIAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjxRRiNmzYoAceeECpqalKTU2Vz+fTW2+95Txv27ZWrVqljIwMJSUladKkSTp+/HjUPiKRiBYuXKhhw4YpOTlZRUVFamhoiKoJhULy+/2yLEuWZcnv9+vixYtdP0oAADDgxBRiRowYoeeee06HDx/W4cOH9fWvf11/+Id/6ASVNWvWaO3ataqoqNChQ4fk9Xo1depUtbS0OPsoLS1VVVWVKisrtXfvXrW2tqqwsFAdHR1OTUlJierr6xUIBBQIBFRfXy+/399NhwwAAAYCdyzFjz76aNTjv/u7v9OGDRtUW1urMWPGaP369Vq5cqVmzZolSdq6das8Ho927typ+fPnKxwOa/Pmzdq2bZumTJkiSdq+fbsyMzO1e/duTZs2TSdPnlQgEFBtba3y8vIkSZs2bZLP59OpU6c0atSo7jhuAABguC5fE9PR0aHKykpdunRJPp9PZ86cUTAYVEFBgVOTmJioiRMnat++fZKkuro6Xb58OaomIyNDOTk5Ts3+/ftlWZYTYCRpwoQJsizLqQEAAIhpJUaSjh49Kp/Pp08++UR33323qqqqNGbMGCdgeDyeqHqPx6P3339fkhQMBpWQkKAhQ4Z0qgkGg05Nenp6p/dNT093am4mEokoEok4j5ubm2M9NAAAYJCYV2JGjRql+vp61dbW6i/+4i80e/ZsnThxwnne5XJF1du23WnsRjfW3Kz+0/ZTXl7uXAhsWZYyMzNv95AAAICBYg4xCQkJ+p3f+R2NHz9e5eXlevDBB/W9731PXq9XkjqtljQ1NTmrM16vV+3t7QqFQresOXfuXKf3PX/+fKdVnt+0YsUKhcNhZzt79myshwYAAAxyx58TY9u2IpGIsrKy5PV6VV1d7TzX3t6umpoa5efnS5Jyc3MVHx8fVdPY2Khjx445NT6fT+FwWAcPHnRqDhw4oHA47NTcTGJionPr9/UNAAAMXDFdE/PXf/3XmjFjhjIzM9XS0qLKykr9/Oc/VyAQkMvlUmlpqcrKypSdna3s7GyVlZVp8ODBKikpkSRZlqU5c+ZoyZIlSktL09ChQ7V06VKNHTvWuVtp9OjRmj59uubOnauNGzdKkubNm6fCwkLuTAIAAI6YQsy5c+fk9/vV2Ngoy7L0wAMPKBAIaOrUqZKkZcuWqa2tTQsWLFAoFFJeXp527dqllJQUZx/r1q2T2+1WcXGx2traNHnyZG3ZskVxcXFOzY4dO7Ro0SLnLqaioiJVVFR0x/ECAIABwmXbtt3XTfSE5uZmWZalcDjcI39aunf5T7p9nz3tvedm9nULwJ27ckn60d3Xfi5uldzJfdsP0E04r1wTy/mb704CAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJFi+gJIAAD6OxO/gwhdw0oMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIzEdyd9hpj4fSLvPTezr1sAAPRTrMQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYKaYQU15erq997WtKSUlRenq6vvGNb+jUqVNRNbZta9WqVcrIyFBSUpImTZqk48ePR9VEIhEtXLhQw4YNU3JysoqKitTQ0BBVEwqF5Pf7ZVmWLMuS3+/XxYsXu3aUAABgwIkpxNTU1OjJJ59UbW2tqqurdeXKFRUUFOjSpUtOzZo1a7R27VpVVFTo0KFD8nq9mjp1qlpaWpya0tJSVVVVqbKyUnv37lVra6sKCwvV0dHh1JSUlKi+vl6BQECBQED19fXy+/3dcMgAAGAgcMdSHAgEoh6/8sorSk9PV11dnX7v935Ptm1r/fr1WrlypWbNmiVJ2rp1qzwej3bu3Kn58+crHA5r8+bN2rZtm6ZMmSJJ2r59uzIzM7V7925NmzZNJ0+eVCAQUG1trfLy8iRJmzZtks/n06lTpzRq1KjuOHYAAGCwO7omJhwOS5KGDh0qSTpz5oyCwaAKCgqcmsTERE2cOFH79u2TJNXV1eny5ctRNRkZGcrJyXFq9u/fL8uynAAjSRMmTJBlWU7NjSKRiJqbm6M2AAAwcHU5xNi2rcWLF+t3f/d3lZOTI0kKBoOSJI/HE1Xr8Xic54LBoBISEjRkyJBb1qSnp3d6z/T0dKfmRuXl5c71M5ZlKTMzs6uHBgAADNDlEPPUU0/pP//zP/XDH/6w03MulyvqsW3bncZudGPNzepvtZ8VK1YoHA4729mzZ2/nMAAAgKG6FGIWLlyoN954Qz/72c80YsQIZ9zr9UpSp9WSpqYmZ3XG6/Wqvb1doVDoljXnzp3r9L7nz5/vtMpzXWJiolJTU6M2AAAwcMUUYmzb1lNPPaXXX39d//Ef/6GsrKyo57OysuT1elVdXe2Mtbe3q6amRvn5+ZKk3NxcxcfHR9U0Njbq2LFjTo3P51M4HNbBgwedmgMHDigcDjs1AADgsy2mu5OefPJJ7dy5U//2b/+mlJQUZ8XFsiwlJSXJ5XKptLRUZWVlys7OVnZ2tsrKyjR48GCVlJQ4tXPmzNGSJUuUlpamoUOHaunSpRo7dqxzt9Lo0aM1ffp0zZ07Vxs3bpQkzZs3T4WFhdyZBAAAJMUYYjZs2CBJmjRpUtT4K6+8om9961uSpGXLlqmtrU0LFixQKBRSXl6edu3apZSUFKd+3bp1crvdKi4uVltbmyZPnqwtW7YoLi7OqdmxY4cWLVrk3MVUVFSkioqKrhwjAAAYgFy2bdt93URPaG5ulmVZCofDPXJ9zL3Lf9Lt+0Rn7z03s69bQH9z5ZL0o7uv/VzcKrmT+7Yf9Dv8+9x7euLf6FjO33x3EgAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgpJg+sRcA8NnCB8ehP2MlBgAAGIkQAwAAjESIAQAARiLEAAAAI3FhL/o1Ey8q5Ju3AaB3sBIDAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEh8izUA9BITv5Ud6M9YiQEAAEZiJQboZib+3/Z7z83s6xYAIGasxAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBJ3JwEw1uj/F1CbPaiv2wDQRwgxAIy6LTzJ9YlOju3rLgD0B/w5CQAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYKeYQ84tf/EKPPvqoMjIy5HK59OMf/zjqedu2tWrVKmVkZCgpKUmTJk3S8ePHo2oikYgWLlyoYcOGKTk5WUVFRWpoaIiqCYVC8vv9sixLlmXJ7/fr4sWLMR8gAAAYmGIOMZcuXdKDDz6oioqKmz6/Zs0arV27VhUVFTp06JC8Xq+mTp2qlpYWp6a0tFRVVVWqrKzU3r171draqsLCQnV0dDg1JSUlqq+vVyAQUCAQUH19vfx+fxcOEQAADEQxf3fSjBkzNGPGjJs+Z9u21q9fr5UrV2rWrFmSpK1bt8rj8Wjnzp2aP3++wuGwNm/erG3btmnKlCmSpO3btyszM1O7d+/WtGnTdPLkSQUCAdXW1iovL0+StGnTJvl8Pp06dUqjRo3q6vECAIABoluviTlz5oyCwaAKCgqcscTERE2cOFH79u2TJNXV1eny5ctRNRkZGcrJyXFq9u/fL8uynAAjSRMmTJBlWU7NjSKRiJqbm6M2AAAwcHVriAkGg5Ikj8cTNe7xeJzngsGgEhISNGTIkFvWpKend9p/enq6U3Oj8vJy5/oZy7KUmZl5x8cDAAD6rx65O8nlckU9tm2709iNbqy5Wf2t9rNixQqFw2FnO3v2bBc6BwAApujWEOP1eiWp02pJU1OTszrj9XrV3t6uUCh0y5pz58512v/58+c7rfJcl5iYqNTU1KgNAAAMXN0aYrKysuT1elVdXe2Mtbe3q6amRvn5+ZKk3NxcxcfHR9U0Njbq2LFjTo3P51M4HNbBgwedmgMHDigcDjs1AADgsy3mu5NaW1v13//9387jM2fOqL6+XkOHDtUXvvAFlZaWqqysTNnZ2crOzlZZWZkGDx6skpISSZJlWZozZ46WLFmitLQ0DR06VEuXLtXYsWOdu5VGjx6t6dOna+7cudq4caMkad68eSosLOTOJAAAIKkLIebw4cP6/d//fefx4sWLJUmzZ8/Wli1btGzZMrW1tWnBggUKhULKy8vTrl27lJKS4rxm3bp1crvdKi4uVltbmyZPnqwtW7YoLi7OqdmxY4cWLVrk3MVUVFT0Wz+bBgAAfPa4bNu2+7qJntDc3CzLshQOh3vk+ph7l/+k2/cJ4NMluT7RybHflCSNPvqa2uxBfdwR8Nn13nMzu32fsZy/+e4kAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARur3Ieall15SVlaWBg0apNzcXO3Zs6evWwIAAP1Avw4xr776qkpLS7Vy5UodOXJEjzzyiGbMmKEPPvigr1sDAAB9rF+HmLVr12rOnDn69re/rdGjR2v9+vXKzMzUhg0b+ro1AADQx9x93cBv097errq6Oi1fvjxqvKCgQPv27etUH4lEFIlEnMfhcFiS1Nzc3CP9XY183CP7BXBrHa5P1Py///l1RD7WVftq3zYEfIb1xDn2+j5t2/7U2n4bYi5cuKCOjg55PJ6ocY/Ho2Aw2Km+vLxcq1ev7jSemZnZYz0C6BuW89Of9WEXAKz1PbfvlpYWWZZ1y5p+G2Kuc7lcUY9t2+40JkkrVqzQ4sWLncdXr17Vr3/9a6Wlpd20/k40NzcrMzNTZ8+eVWpqarfuG/+Hee4dzHPvYJ57D3PdO3pqnm3bVktLizIyMj61tt+GmGHDhikuLq7TqktTU1On1RlJSkxMVGJiYtTY5z73uZ5sUampqfwH0guY597BPPcO5rn3MNe9oyfm+dNWYK7rtxf2JiQkKDc3V9XV1VHj1dXVys/P76OuAABAf9FvV2IkafHixfL7/Ro/frx8Pp9efvllffDBB3riiSf6ujUAANDH+nWIeeyxx/TRRx/pu9/9rhobG5WTk6M333xTI0eO7NO+EhMT9cwzz3T68xW6F/PcO5jn3sE89x7munf0h3l22bdzDxMAAEA/02+viQEAALgVQgwAADASIQYAABiJEAMAAIxEiLmJl156SVlZWRo0aJByc3O1Z8+eW9bX1NQoNzdXgwYN0n333ad//Md/7KVOzRfLXL/++uuaOnWq7rnnHqWmpsrn8+mnP/1pL3Zrrlh/p697++235Xa79ZWvfKVnGxwgYp3nSCSilStXauTIkUpMTNQXv/hF/fM//3MvdWuuWOd5x44devDBBzV48GANHz5cf/7nf66PPvqol7o10y9+8Qs9+uijysjIkMvl0o9//ONPfU2fnAttRKmsrLTj4+PtTZs22SdOnLCffvppOzk52X7//fdvWn/69Gl78ODB9tNPP22fOHHC3rRpkx0fH2+/9tprvdy5eWKd66efftp+/vnn7YMHD9rvvPOOvWLFCjs+Pt7+5S9/2cudmyXWeb7u4sWL9n333WcXFBTYDz74YO80a7CuzHNRUZGdl5dnV1dX22fOnLEPHDhgv/32273YtXlinec9e/bYd911l/29733PPn36tL1nzx77y1/+sv2Nb3yjlzs3y5tvvmmvXLnS/td//Vdbkl1VVXXL+r46FxJibvDQQw/ZTzzxRNTYl770JXv58uU3rV+2bJn9pS99KWps/vz59oQJE3qsx4Ei1rm+mTFjxtirV6/u7tYGlK7O82OPPWb/zd/8jf3MM88QYm5DrPP81ltv2ZZl2R999FFvtDdgxDrPf//3f2/fd999UWMvvviiPWLEiB7rcaC5nRDTV+dC/pz0G9rb21VXV6eCgoKo8YKCAu3bt++mr9m/f3+n+mnTpunw4cO6fPlyj/Vquq7M9Y2uXr2qlpYWDR06tCdaHBC6Os+vvPKKfvWrX+mZZ57p6RYHhK7M8xtvvKHx48drzZo1+vznP6/7779fS5cuVVtbW2+0bKSuzHN+fr4aGhr05ptvyrZtnTt3Tq+99ppmzpzZGy1/ZvTVubBff2Jvb7tw4YI6Ojo6fcGkx+Pp9EWU1wWDwZvWX7lyRRcuXNDw4cN7rF+TdWWub/TCCy/o0qVLKi4u7okWB4SuzPO7776r5cuXa8+ePXK7+SfidnRlnk+fPq29e/dq0KBBqqqq0oULF7RgwQL9+te/5rqY36Ir85yfn68dO3boscce0yeffKIrV66oqKhI//AP/9AbLX9m9NW5kJWYm3C5XFGPbdvuNPZp9TcbR2exzvV1P/zhD7Vq1Sq9+uqrSk9P76n2BozbneeOjg6VlJRo9erVuv/++3urvQEjlt/nq1evyuVyaceOHXrooYf0B3/wB1q7dq22bNnCasyniGWeT5w4oUWLFulv//ZvVVdXp0AgoDNnzvAdfD2gL86F/G/Wbxg2bJji4uI6JfqmpqZOCfM6r9d703q32620tLQe69V0XZnr61599VXNmTNH//Iv/6IpU6b0ZJvGi3WeW1padPjwYR05ckRPPfWUpGsnW9u25Xa7tWvXLn3961/vld5N0pXf5+HDh+vzn/+8LMtyxkaPHi3bttXQ0KDs7Owe7dlEXZnn8vJyPfzww/rLv/xLSdIDDzyg5ORkPfLII3r22WdZLe8mfXUuZCXmNyQkJCg3N1fV1dVR49XV1crPz7/pa3w+X6f6Xbt2afz48YqPj++xXk3XlbmWrq3AfOtb39LOnTv5m/ZtiHWeU1NTdfToUdXX1zvbE088oVGjRqm+vl55eXm91bpRuvL7/PDDD+vDDz9Ua2urM/bOO+/orrvu0ogRI3q0X1N1ZZ4//vhj3XVX9KkuLi5O0v+tFODO9dm5sEcvGzbQ9dv3Nm/ebJ84ccIuLS21k5OT7ffee8+2bdtevny57ff7nfrrt5V95zvfsU+cOGFv3ryZW6xvU6xzvXPnTtvtdtvf//737cbGRme7ePFiXx2CEWKd5xtxd9LtiXWeW1pa7BEjRtjf/OY37ePHj9s1NTV2dna2/e1vf7uvDsEIsc7zK6+8Yrvdbvull16yf/WrX9l79+61x48fbz/00EN9dQhGaGlpsY8cOWIfOXLElmSvXbvWPnLkiHMre385FxJibuL73/++PXLkSDshIcH+6le/atfU1DjPzZ492544cWJU/c9//nN73LhxdkJCgn3vvffaGzZs6OWOzRXLXE+cONGW1GmbPXt27zdumFh/p38TIeb2xTrPJ0+etKdMmWInJSXZI0aMsBcvXmx//PHHvdy1eWKd5xdffNEeM2aMnZSUZA8fPtx+/PHH7YaGhl7u2iw/+9nPbvnvbX85F7psm/U0AABgHq6JAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBI/x/tS5E+MCuF/gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hat = model.predict(X_valid)\n",
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f489fabe-4fca-4f15-b67e-84fc9f2cfe48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'92.09'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(roc_auc_score(y_valid, y_hat)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9133b10b-1d47-4ae7-a000-e1024221e47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
